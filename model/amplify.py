# ---------------------------
# 1. è¼‰å…¥ MobileIE Full æ¨¡å‹
# ---------------------------
import sys
sys.path.append("/content/MobileIE")

from model.lle import MobileIELLENet # â˜… ä½¿ç”¨ Full æ¨¡å‹ï¼Œè€Œä¸æ˜¯ Slimï¼
device = "cuda" if torch.cuda.is_available() else "cpu"
print("ä½¿ç”¨è£ç½®ï¼š", device)

# â˜… ä½¿ç”¨ Full æ¨¡å‹çµæ§‹
mobileie = MobileIELLENet(channels=12)

# â˜… è¼‰å…¥çµ„å“¡è¨“ç·´çš„æ¬Šé‡
state = torch.load("/content/model_best.pkl", map_location=device)

# â˜… strict=Falseï¼šé¿å… tail_warmã€conv_bn ç­‰ Full model å…§çš„é¡å¤–å±¤ mismatch
mobileie.load_state_dict(state, strict=False)

mobileie = mobileie.to(device).eval()
for p in mobileie.parameters():
p.requires_grad = False

print("âœ” MobileIE Full æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")


# ---------------------------
# 2. Baseline æ¨è«–
# ---------------------------
def run_baseline(img_rgb):
    """MobileIE åŸå§‹è¼¸å‡º"""
    t = to_tensor(img_rgb.copy()).unsqueeze(0).to(device)
    with torch.no_grad():
        out = mobileie(t).clamp(0,1)[0].cpu()
    return np.array(to_pil_image(out)).astype(np.uint8)


# ---------------------------
# 3. Loc v3 â€” æš—éƒ¨å¢äº® + å°æ¯”è£œå„Ÿ + é«˜å…‰ä¿è­·
# ---------------------------
def smoothstep(e0, e1, x):
    t = np.clip((x - e0) / (e1 - e0), 0, 1)
    return t * t * (3 - 2 * t)

def dark_mask(img_rgb, dark_thr=0.55, low=0.20, high=0.65):
    """ç”Ÿæˆæš—éƒ¨ soft maskï¼šæš—çš„åœ°æ–¹ç‚º 1ï¼Œäº®éƒ¨æ¥è¿‘ 0"""
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) / 255.0
    inv = np.clip((dark_thr - gray) / dark_thr, 0, 1)
    m = smoothstep(low, high, inv)
    return np.stack([m]*3, axis=-1)

def restore_local_contrast(img_rgb, amount=0.12, sigma=4.0):
    """ç°¡å–® local contrastï¼ˆunsharp maskï¼‰"""
    blur = cv2.GaussianBlur(img_rgb, (0,0), sigmaX=sigma)
    out = img_rgb.astype(np.float32) + amount * (img_rgb.astype(np.float32) - blur.astype(np.float32))
    return np.clip(out, 0, 255).astype(np.uint8)

def protect_highlights(img_rgb, strength=0.25):
    """å£“ä¸€ä¸‹é«˜å…‰ï¼Œé¿å…å¤ªæ­»ç™½ï¼›é¡ä¼¼ HDR tone mapping"""
    img_f = img_rgb.astype(np.float32) / 255.0
    out = img_f / (img_f + strength) # x / (x + c)
    return np.clip(out * 255.0, 0, 255).astype(np.uint8)

def gray_world_balance(img_rgb, mix=0.4):
    """ç°¡å–®é˜²åè‰²ï¼šè®“ä¸‰é€šé“å¹³å‡å€¼æ¥è¿‘"""
    img = img_rgb.astype(np.float32)
    mean_c = img.mean(axis=(0,1), keepdims=True) + 1e-6
    mean_all = img.mean() + 1e-6
    gain = mean_all / mean_c # R/G/B å„è‡ªèª¿æ•´
    balanced = img * (1.0 * (1-mix) + gain * mix)
    return np.clip(balanced, 0, 255).astype(np.uint8)

def run_loc_v3(original_rgb,
boost_strength=0.16, # åŸæœ¬ 0.24 â†’ é™ä½å¢äº®å¹…åº¦
dark_thr=0.48, # åŸæœ¬ 0.55~0.65 â†’ é™ä½ã€Œæš—éƒ¨ã€è¦†è“‹
low=0.20,
high=0.70,
restore_local_contrast_amount = 0.15,
restore_local_contrast_sigma = 4.0,
protect_highlights_strength = 0.15,
gray_world_balance_mix = 0.30): # è®“ mask æ›´æŸ”å’Œ
    base = run_baseline(original_rgb)

    mask = dark_mask(original_rgb, dark_thr, low, high)
    diff = base.astype(np.float32) - original_rgb.astype(np.float32)

    # (1) æš—éƒ¨å¢äº®ï¼ˆå¼±åŒ–ï¼‰
    out = original_rgb.astype(np.float32) + mask * diff * boost_strength
    out = np.clip(out, 0, 255).astype(np.uint8)

    # (2) å°æ¯”æ¢å¾©ï¼ˆå¼·åŒ–ï¼‰
    out = restore_local_contrast(out, amount=restore_local_contrast_amount, sigma=restore_local_contrast_sigma)

    # (3) é«˜å…‰ä¿ç•™ï¼ˆå¼±åŒ–å£“åˆ¶ï¼‰
    out = protect_highlights(out, strength=protect_highlights_strength)

    # (4) é˜²åè‰²ï¼ˆé™ä½å¼·åº¦ï¼‰
    out = gray_world_balance(out, mix=gray_world_balance_mix)

    return out, base



# ---------------------------
# 4. AutoSelect v4 â€” æ›´è°æ˜é¸æ“‡ base / loc_v3
# ---------------------------
def compute_gray(img_rgb):
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) / 255.0
    return gray.astype(np.float32) # â˜… åŠ é€™è¡Œ


def edge_strength(gray):
    """Sobel é‚Šç·£å¼·åº¦"""
    gray = gray.astype(np.float32) # â˜…â˜…â˜… å¼·åˆ¶è™•ç† dtype
    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    mag = np.sqrt(gx*gx + gy*gy)
    return float(mag.mean())


def auto_select_v4(original_rgb, base_rgb, loc_rgb):
    """
    AutoSelect v4.2 â€” åŠ å…¥ baseline failure detectionï¼š
    âœ” baseline è‰²åéå¤§
    âœ” baseline è®Šè² ç‰‡ï¼ˆå¤§éƒ¨åˆ†æ¯”åŸåœ–é‚„æš—ï¼‰
    âœ” baseline çˆ†ç™½å¤ªå¤š
    è‹¥åµæ¸¬ç•°å¸¸ â†’ å¼·åˆ¶ä½¿ç”¨ loc_v3
    """

    # ---------- åŸºæœ¬ç°éš ----------
    g_o = compute_gray(original_rgb)
    g_b = compute_gray(base_rgb)
    g_l = compute_gray(loc_rgb)

    # ========== åŸºç¤çµ±è¨ˆ ==========
    mean_o = float(g_o.mean())
    bright_o = float((g_o > 0.85).mean())
    contrast_o = float(g_o.std())

    mean_b = float(g_b.mean())
    bright_b = float((g_b > 0.85).mean())
    contrast_b = float(g_b.std())

    mean_l = float(g_l.mean())
    bright_l = float((g_l > 0.85).mean())
    contrast_l = float(g_l.std())

    # ---------- baseline çš„äº®éƒ¨æ“´æ•£ ----------
    bright_spread = bright_b - bright_o

    # ---------- é‚Šç·£æŒ‡æ¨™ ----------
    edge_o = edge_strength(g_o)
    edge_b = edge_strength(g_b)
    edge_l = edge_strength(g_l)

    edge_loss_base = (edge_o - edge_b) / max(edge_o, 1e-6)
    edge_loss_loc = (edge_o - edge_l) / max(edge_o, 1e-6)

    # ===================================================================
    # NEW: Baseline Failure Detectionï¼ˆæ ¸å¿ƒæ”¹å–„ï¼‰
    # ===================================================================

    # (A) baseline èˆ‡åŸåœ–å·®ç•°å¤ªå¤§ â†’ åè‰² or å…‰èª¿å´©å£
    color_shift = np.mean(np.abs(base_rgb.astype(float) - original_rgb.astype(float)) / 255.0)

    # (B) baseline è®Šè² ç‰‡ â†’ å¤§éƒ¨åˆ†åƒç´ æ¯”åŸåœ–æ›´æš—
    neg_score = np.mean(base_rgb.mean(axis=2) < original_rgb.mean(axis=2))

    # (C) baseline éæ›ï¼ˆå¤ªç™½ï¼‰
    over_b = np.mean(base_rgb > 245)

    baseline_fail = (
        (color_shift > 0.22) or # è‰²åéå¤§
        (neg_score > 0.60) or # é¡è² ç‰‡
        (over_b > 0.25) # è¶…é 25% éæ›
    )

    if baseline_fail:
        mode = "loc_v3"
    else:
    # ===================================================================
    # æ—¢æœ‰é‚è¼¯ï¼ˆä¿ç•™ä½ çš„ v4ï¼Œä½†æ›´ç©©å®šï¼‰
    # ===================================================================

        if bright_spread > 0.10 and contrast_o > 0.18:
            mode = "loc_v3"

        elif edge_loss_base > 0.25:
            mode = "loc_v3"

        elif contrast_l < 0.6 * contrast_o:
            mode = "base"

        elif mean_o < 0.22 and bright_b > 0.12:
            mode = "loc_v3"

        else:
            mode = "base"

    # æœ€çµ‚é¸æ“‡
    final = loc_rgb if mode == "loc_v3" else base_rgb

    # å›å‚³ debug è³‡è¨Š
    info = dict(
        mean_o=mean_o, mean_b=mean_b, mean_l=mean_l,
        bright_o=bright_o, bright_b=bright_b, bright_l=bright_l,
        contrast_o=contrast_o, contrast_b=contrast_b, contrast_l=contrast_l,
        bright_spread=bright_spread,
        edge_o=edge_o, edge_b=edge_b, edge_l=edge_l,
        edge_loss_base=edge_loss_base,
        edge_loss_loc=edge_loss_loc,
        color_shift=color_shift,
        neg_score=neg_score,
        over_b=over_b,
        baseline_fail=baseline_fail
    )

    return final, mode, info



# ---------------------------
# 5. å–®å¼µåœ–ç‰‡ï¼šcompare å››åœ–
# ---------------------------
def show_compare(path, resize_to=None):
    bgr = cv2.imread(path)
    if bgr is None:
        print("âŒ ç„¡æ³•è®€å–åœ–ç‰‡ï¼š", path)
        return
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    if resize_to is not None:
        rgb = cv2.resize(rgb, (resize_to, resize_to))

    loc3, base = run_loc_v3(rgb)
    final, mode, info = auto_select_v4(rgb, base, loc3)

    print("\n==============================")
    print("ğŸ“Œ åœ–ç‰‡ï¼š", path)
    print(f"mean_o={info['mean_o']:.3f}, contrast_o={info['contrast_o']:.3f}")
    print(f"bright_o={info['bright_o']:.3f}, bright_b={info['bright_b']:.3f}, bright_l={info['bright_l']:.3f}")
    print(f"bright_spread={info['bright_spread']:.3f}")
    print(f"edge_o={info['edge_o']:.3f}, edge_b={info['edge_b']:.3f}, edge_l={info['edge_l']:.3f}")
    print(f"edge_loss_base={info['edge_loss_base']:.3f}, edge_loss_loc={info['edge_loss_loc']:.3f}")
    print(f"ğŸ‘‰ AutoSelect v4 æ¨¡å¼ï¼š{mode}")
    print("==============================")

    plt.figure(figsize=(20,6))
    plt.subplot(1,4,1); plt.imshow(rgb); plt.title("Original"); plt.axis("off")
    plt.subplot(1,4,2); plt.imshow(base); plt.title("MobileIE Base"); plt.axis("off")
    plt.subplot(1,4,3); plt.imshow(loc3); plt.title("Loc v3"); plt.axis("off")
    plt.subplot(1,4,4); plt.imshow(final);plt.title(f"Final ({mode})"); plt.axis("off")
    plt.show()


    print("\nâœ… Loc v3 + AutoSelect v4 å·²è¨­å®šå®Œæˆï¼Œä½ å¯ä»¥ç”¨ show_compare() ä¾†æ¸¬åœ–ã€‚")

    # æˆ‘è‡ªå·±çš„æ¸¬è©¦é›†è·¯å¾‘(è¨˜å¾—æ”¹)
    exdark_root = "/content/contrast_dataset/ExDark"
    paths = []
    for cls in os.listdir(exdark_root):
        d = os.path.join(exdark_root, cls)
        if os.path.isdir(d):
            paths += glob.glob(d + "/*.jpg") + glob.glob(d + "/*.png")

    print("ExDark åœ–ç‰‡æ•¸ï¼š", len(paths))
    for p in random.sample(paths, 10):
        show_compare(p, resize_to=256)